{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c461633a",
   "metadata": {},
   "source": [
    "### Enter full names of group members:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4648c5",
   "metadata": {},
   "source": [
    "##### Name A:\n",
    "##### Name B:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 73,
=======
   "execution_count": 435,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": 435,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "30d55dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from sympy import prime\n",
    "from pathlib import Path  # for paths of files\n",
    "import csv\n",
    "import copy\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ANSI escape codes for colors\n",
    "class colors:\n",
    "    red = '\\033[91m'\n",
    "    green = '\\033[92m'\n",
    "    blue = '\\033[94m'\n",
    "    end = '\\033[0m'  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d4a780",
   "metadata": {},
   "source": [
    "### 1. DGIM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9287695e",
   "metadata": {},
   "source": [
    "#### 1.1. DGIM algorithm"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 104,
=======
   "execution_count": 436,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": 436,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "2af55744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default DGIM parameters\n",
    "\n",
    "stream_path = 'data/my_stream.txt'\n",
    "\n",
    "# The window size\n",
    "N = 500 "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 119,
=======
   "execution_count": 437,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": 437,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "3f339cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dgim_algorithm(stream_path, N):\n",
    "    \n",
    "    buckets = []\n",
    "    current_timestamp = 0\n",
    "\n",
    "    def update_buckets():\n",
    "        i = 0\n",
    "        while i < len(buckets) - 1:\n",
    "            if i < len(buckets) - 1 and buckets[i][0] == buckets[i+1][0]:\n",
    "                if i + 2 < len(buckets) and buckets[i][0] == buckets[i+2][0]:\n",
    "                    # Merge the two oldest buckets\n",
    "                    new_size = buckets[i][0] + buckets[i+1][0]\n",
    "                    new_timestamp = buckets[i+1][1]\n",
    "                    buckets.pop(i)\n",
    "                    buckets[i] = (new_size, new_timestamp)\n",
    "                else:\n",
    "                    i += 1\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "    def remove_old_buckets():\n",
    "        # Remove buckets that are older than the window size N\n",
    "        threshold_timestamp = current_timestamp - N\n",
    "        while buckets and buckets[-1][1] <= threshold_timestamp:\n",
    "            buckets.pop()\n",
    "    \n",
    "    \n",
    "    # Loop through the entire data stream, one bit at a time\n",
    "    with open(stream_path) as f:\n",
    "        while True:\n",
    "            bit = f.read(1)\n",
    "            \n",
    "            # Clause to break while loop at the end of the stream\n",
    "            if not bit:\n",
    "                break\n",
    "              \n",
    "            # To-do! update timestamp\n",
    "            current_timestamp += 1\n",
    "            current_timestamp = current_timestamp % N\n",
    "            \n",
    "            # To-do! implement the dgim algorithm here\n",
    "\n",
    "            if bit == '1':\n",
    "                buckets.insert(0, (1, current_timestamp))\n",
    "                update_buckets()\n",
    "\n",
    "            remove_old_buckets()\n",
    "            \n",
    "    end_timestamp = buckets[0][1] if buckets else current_timestamp\n",
    "\n",
    "    return buckets, end_timestamp"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 120,
=======
   "execution_count": 438,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": 438,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "6dc1d2b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bucket \u001b[38;5;241m=\u001b[39m \u001b[43mdgim_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[119], line 45\u001b[0m, in \u001b[0;36mdgim_algorithm\u001b[0;34m(stream_path, N)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m bit \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     44\u001b[0m             buckets\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, (\u001b[38;5;241m1\u001b[39m, current_timestamp))\n\u001b[0;32m---> 45\u001b[0m             \u001b[43mupdate_buckets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m         remove_old_buckets()\n\u001b[1;32m     49\u001b[0m end_timestamp \u001b[38;5;241m=\u001b[39m buckets[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m buckets \u001b[38;5;28;01melse\u001b[39;00m current_timestamp\n",
      "Cell \u001b[0;32mIn[119], line 8\u001b[0m, in \u001b[0;36mdgim_algorithm.<locals>.update_buckets\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_buckets\u001b[39m():\n\u001b[1;32m      7\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuckets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(buckets) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m buckets[i][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m buckets[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m     10\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(buckets) \u001b[38;5;129;01mand\u001b[39;00m buckets[i][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m buckets[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m     11\u001b[0m                 \u001b[38;5;66;03m# Merge the two oldest buckets\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bucket = dgim_algorithm(stream_path, N)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 118,
=======
   "execution_count": 439,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": 439,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "6966be95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated list of timestamps buckets from DGIM algorithm: \n",
      " []\n",
      "The end timestamp: 1010102\n"
     ]
    }
   ],
   "source": [
    "print(f\"The updated list of timestamps buckets from DGIM algorithm: \\n {bucket[0]}\")\n",
    "print(f\"The end timestamp: {bucket[1]}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c273257",
   "metadata": {},
   "source": [
    "#### 1.2. Query the Bucket "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 77,
=======
   "execution_count": 440,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": 440,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "4cb0343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_count(stream_path, k):\n",
    "    stream_list = []\n",
    "    with open(stream_path, 'r') as file:\n",
    "        for line in file:\n",
    "            stream_list.extend(list(map(int, line.strip())))\n",
    "\n",
    "    # Convert the list into a numpy array\n",
    "    stream_array = np.array(stream_list)\n",
    "    \n",
    "    return int(np.sum(stream_array[-k:]))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 43,
=======
   "execution_count": 441,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": 441,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "7f7f130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dgim_query(bucket, N, k):  \n",
    "    \n",
    "    # Extract the buckets and the end timestamp\n",
    "    bucket_list, end_time_stamp = bucket\n",
    "   \n",
    "    \n",
    "    # To-do! initialize the different variables\n",
    "    \n",
    "\n",
    "    # To-do! query the dgim bucket using the k parameters\n",
    "    \n",
    "    \n",
    "    return math.ceil(one_count)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 442,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": 442,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "387e5be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of queries\n",
    "K = [10, 50, 100, 300, 500] "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 443,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": 443,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "7702bc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------\n",
      "The total 1s in the last 10 bits by DGIM: 4\n",
      "The true count of 1s in the last 10 bits: 5\n",
      "The DGIM error for predicted 1s in the last 10 bits:     20.0 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 50 bits by DGIM: 25\n",
      "The true count of 1s in the last 50 bits: 26\n",
      "The DGIM error for predicted 1s in the last 50 bits:     3.85 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 100 bits by DGIM: 61\n",
      "The true count of 1s in the last 100 bits: 51\n",
      "The DGIM error for predicted 1s in the last 100 bits:     19.61 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 300 bits by DGIM: 173\n",
      "The true count of 1s in the last 300 bits: 150\n",
      "The DGIM error for predicted 1s in the last 300 bits:     15.33 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 500 bits by DGIM: 269\n",
      "The true count of 1s in the last 500 bits: 241\n",
      "The DGIM error for predicted 1s in the last 500 bits:     11.62 %\n",
      "---------------------------------------------------------------\n"
     ]
<<<<<<< HEAD
<<<<<<< HEAD
=======
=======
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
    },
    {
     "ename": "NameError",
     "evalue": "name 'one_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[443], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---------------------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m K:\n\u001b[0;32m----> 3\u001b[0m     dgim_count \u001b[38;5;241m=\u001b[39m \u001b[43mdgim_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     true_count \u001b[38;5;241m=\u001b[39m actual_count(stream_path, k)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe total 1s in the last \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bits by DGIM: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdgim_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[441], line 13\u001b[0m, in \u001b[0;36mdgim_query\u001b[0;34m(bucket, N, k)\u001b[0m\n\u001b[1;32m      4\u001b[0m bucket_list, end_time_stamp \u001b[38;5;241m=\u001b[39m bucket\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# To-do! initialize the different variables\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# To-do! query the dgim bucket using the k parameters\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m math\u001b[38;5;241m.\u001b[39mceil(\u001b[43mone_count\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'one_count' is not defined"
     ]
<<<<<<< HEAD
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
    }
   ],
   "source": [
    "print(\"---------------------------------------------------------------\")\n",
    "for k in K:\n",
    "    dgim_count = dgim_query(bucket, 500, k)\n",
    "    true_count = actual_count(stream_path, k)\n",
    "    \n",
    "    print(f\"The total 1s in the last {k} bits by DGIM: {dgim_count}\")\n",
    "    print(f\"The true count of 1s in the last {k} bits: {true_count}\")\n",
    "    print(f\"The DGIM error for predicted 1s in the last {k} bits: \\\n",
    "    {round(abs(100*(dgim_count-true_count))/true_count,2)} %\")\n",
    "    print(\"---------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaaceac",
   "metadata": {},
   "source": [
    "### 2. Bloom filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "92883c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Username data for the creation of bloom filters - B\n",
    "data_file = (Path(\"data/bloom_username\").with_suffix('.csv'))\n",
    "\n",
    "# Test data to check the functionality and false positive rate\n",
    "test1_file = (Path(\"data/test1_username\").with_suffix('.csv'))\n",
    "test2_file = (Path(\"data/test2_username\").with_suffix('.csv'))\n",
    "\n",
    "# Default bloom filter parameters\n",
    "bloom_size = 1500000 # parameter N\n",
    "h = 3 # number of hash functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6c5e5c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of bloom filter with zeros\n",
    "B = np.zeros(bloom_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1c033746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d73d660",
   "metadata": {},
   "source": [
    "#### 2.1. Create Bloom filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "75b69edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hash(h, N):\n",
    "    hash_list = []\n",
    "    primes = [114649, 914843, 1382753]\n",
    "    for j in range(h):\n",
    "        hash_list.append(lambda s, j=j: sum(ord(s[i]) * primes[j]**i for i in range(len(s))) % N)\n",
    "    return hash_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a75aeecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = generate_hash(h, bloom_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0d2d4c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bloom_filter(B, hashes, data):\n",
    "    with data.open() as f:\n",
    "        for name in f:\n",
    "            for hash in hashes:\n",
    "                B[hash(name)] = 1\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fe79b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "bloom_array = create_bloom_filter(B, hashes, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d7ce957d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloom_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff48616",
   "metadata": {},
   "source": [
    "#### 2.2. Verify usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "530485d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_verify_username(bloom_array, hashes, new_user):\n",
    "    \n",
    "    # To-do! verify username and return a code of 0 or 1 (1 - username taken and 0 - username available)\n",
    "    for hash in hashes:\n",
    "        if (bloom_array[hash(new_user)] == 0):\n",
    "            return 0\n",
    "    return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b6edf315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to test different usernames here\n",
    "\n",
    "# new_username = \"KazeemTDT4305\"\n",
    "\n",
    "new_username = \"jlrsjrvljvrewrw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "22690d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_code = single_verify_username(bloom_array, hashes, new_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b7730361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mUsername jlrsjrvljvrewrw has been taken. Try again!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if user_code == 1:\n",
    "    print(colors.red + f\"Username {new_username} has been taken. Try again!\" + colors.end)\n",
    "elif user_code == 0:\n",
    "    print(colors.green + f\"Username {new_username} is available. Congrats!\" + colors.end)\n",
    "else:\n",
    "    print(colors.blue + f\"Wrong pass code. Please reverify!\" + colors.end)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "080d7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_verify_username(bloom_array, hashes, data):\n",
    "    # Initialize counts\n",
    "    total_name = 0\n",
    "    taken_name = 0\n",
    "    \n",
    "    with data.open() as f:\n",
    "        for name in f:\n",
    "            hash_hit_count = 0\n",
    "            for hash in hashes:\n",
    "                if (bloom_array[hash(name)] == 0):\n",
    "                    break\n",
    "                elif (bloom_array[hash(name)] == 1):\n",
    "                    hash_hit_count += 1\n",
    "            total_name += 1\n",
    "            if (hash_hit_count == 3):\n",
    "                taken_name += 1\n",
    "            \n",
    "    return round(taken_name/total_name*100,2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4725c4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "Percentage of username seen before from test 1: 100.0%\n",
      "----------------------------------------------------------\n",
      "Percentage of username seen before from test 2: 24.0%\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------------------------------\")\n",
    "user_total = group_verify_username(bloom_array, hashes, test1_file)\n",
    "print(f\"Percentage of username seen before from test 1: {user_total}%\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "user_total = group_verify_username(bloom_array, hashes, test2_file)\n",
    "print(f\"Percentage of username seen before from test 2: {user_total}%\")\n",
    "print(\"----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9488c00b",
   "metadata": {},
   "source": [
    "### 3. Flajolet-Martin"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 37,
=======
   "execution_count": null,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": null,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "dae74f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flajolet_martin(input_stream):\n",
    "    R = 0  # Initialize maximum rightmost zero bit position to 0\n",
    "\n",
    "    # To-do! Define hash function h(x) = 6x + 1 mod 5\n",
    "    hash_func = lambda x: (6 * x + 1) % 5\n",
    "\n",
    "    # To-do! Iterate over the input stream and update maximum rightmost zero bit position\n",
    "    for element in input_stream:\n",
    "        hash_value = hash_func(element)\n",
    "        print(hash_value)\n",
    "        binary_hash = bin(hash_value)[2:]\n",
    "        print(binary_hash)\n",
    "\n",
    "    # Estimate the number of distinct elements\n",
    "    distinct_estimate = 2 ** R\n",
    "\n",
    "    return distinct_estimate"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 38,
=======
   "execution_count": null,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": null,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "c7a283b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
=======
=======
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
      "2\n",
      "10\n",
      "2\n",
      "10\n",
      "3\n",
      "11\n",
      "2\n",
      "10\n",
      "3\n",
      "11\n",
      "2\n",
      "10\n",
      "2\n",
      "10\n",
      "2\n",
      "10\n",
      "2\n",
      "10\n",
      "3\n",
      "11\n",
      "2\n",
      "10\n",
      "2\n",
      "10\n",
      "2\n",
      "10\n",
      "4\n",
      "100\n",
      "3\n",
      "11\n",
      "2\n",
      "10\n",
      "3\n",
      "11\n",
      "4\n",
      "100\n",
      "0\n",
      "0\n",
      "4\n",
      "100\n",
      "2\n",
      "10\n",
      "3\n",
      "11\n",
      "4\n",
      "100\n",
      "2\n",
      "10\n",
<<<<<<< HEAD
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
      "-----------------------------------------------------\n",
      "Distinct elements (estimated) in input stream 1: 1\n",
      "-----------------------------------------------------\n",
      "Distinct elements (estimated) in input stream 2: 1\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Input stream\n",
    "input_stream1 = [1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1]\n",
    "input_stream2 = [1, 3, 2, 1, 2, 3, 4, 3, 1, 2, 3, 1]\n",
    "\n",
    "# Run the Flajolet-Martin algorithm\n",
    "distinct_estimate1 = flajolet_martin(input_stream1)\n",
    "distinct_estimate2 = flajolet_martin(input_stream2)\n",
    "\n",
    "# Print the estimated number of distinct elements\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(f\"Distinct elements (estimated) in input stream 1:\", distinct_estimate1)\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(f\"Distinct elements (estimated) in input stream 2:\", distinct_estimate2)\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3051ee5",
   "metadata": {},
   "source": [
    "### 4. Adword "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805b08ba",
   "metadata": {},
   "source": [
    "#### 4.1. Greedy Algorithm"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 40,
=======
   "execution_count": 684,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": 684,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "a58d6ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User queries\n",
    "queries = [\"big data\", \"big data\", \"big data\",\"bloom filters\", \"bloom filters\", \"bloom filters\",\n",
    "           \"flajolet martin\", \"flajolet martin\", \"flajolet martin\", \"dgim algorithm\", \"dgim algorithm\", \"dgim algorithm\"]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 41,
=======
   "execution_count": 685,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": 685,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "66ee11dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Company A B C and D keywords and budget $$$\n",
    "global_companies = {\n",
    "        'A': [\"big data\", \"bloom filters\", 3],\n",
    "        'B': [\"flajolet martin\", 3],\n",
    "        'C': [\"flajolet martin\", \"dgim algorithm\", 3],\n",
    "        'D': [\"big data\", 3],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 28,
=======
   "execution_count": 686,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": 686,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "fd6eb986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "\n",
    "def greedy_algorithm(local_companies, queries):\n",
    "    # setter revenue til 0\n",
    "    revenue = 0\n",
    "    \n",
    "    # For-løkke gjennom spørringene som setter selskapene med ord som matcher i en liste\n",
    "    for q in queries:\n",
    "        matched_companies = []\n",
    "        \n",
    "        # Company er A, B, C, D og data er tilhørende data i local_companies dictionary.\n",
    "        for company, data in local_companies.items():\n",
    "            keywords = data[:-1]  # Keywords er alle elementene utenom det siste derfor det er :-1\n",
    "            budget = data[-1]      # budget er det siste elementet derfor -1\n",
    "            # legger til elementene som har $$\n",
    "            if budget > 0 and q in keywords:\n",
    "                matched_companies.append(company)\n",
    "    \n",
    "        # Velger bare et random selskap fra listen som matcher og har budsjett over 0\n",
    "        if matched_companies:\n",
    "            selected_company = random.choice(matched_companies)\n",
    "            local_companies[selected_company][-1] -= 1  #Trekker fra 1 i budsjettet\n",
    "            revenue += 1\n",
    "    \n",
    "    return revenue\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 29,
=======
   "execution_count": 672,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": 672,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "7c9378f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trials using Greedy Algorithm...\n",
      "------------------------------------------------\n",
      "Trial 1 - Revenue generated: 8\n",
      "Trial 2 - Revenue generated: 10\n",
      "Trial 3 - Revenue generated: 8\n",
      "Trial 4 - Revenue generated: 9\n",
      "Trial 5 - Revenue generated: 7\n",
      "Trial 6 - Revenue generated: 9\n",
      "Trial 7 - Revenue generated: 11\n",
      "Trial 8 - Revenue generated: 9\n",
      "Trial 9 - Revenue generated: 10\n",
      "Trial 10 - Revenue generated: 10\n",
      "------------------------------------------------\n",
      "Average revenue generated for all trials:  9.1\n"
     ]
    }
   ],
   "source": [
    "total_revenue = 0\n",
    "total_trials = 10\n",
    "print(\"Starting trials using Greedy Algorithm...\")\n",
    "print(\"------------------------------------------------\")\n",
    "for i in range(total_trials):\n",
    "    local_companies = copy.deepcopy(global_companies)\n",
    "    revenue = greedy_algorithm(local_companies, queries)\n",
    "    total_revenue = total_revenue + revenue\n",
    "    print(f\"Trial {i+1} - Revenue generated: {revenue}\")\n",
    "print(\"------------------------------------------------\")   \n",
    "print(\"Average revenue generated for all trials: \",total_revenue/total_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49fda97",
   "metadata": {},
   "source": [
    "#### 4.2. Balance Algorithm"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 675,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": 675,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "9af1b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#blabla\n",
    "def balance_algorithm(local_companies, queries):\n",
    "    #Helt lik start på koden\n",
    "    revenue = 0\n",
    "    \n",
    "    for q in queries:\n",
    "        matched_companies = []\n",
    "\n",
    "        for company, data in local_companies.items():\n",
    "            keywords = data[:-1]  \n",
    "            budget = data[-1]     \n",
    "            \n",
    "            if budget > 0 and q in keywords:\n",
    "                matched_companies.append((company, budget))  # Legger også til budsjett i listen\n",
    "        \n",
    "        if matched_companies:\n",
    "            # Sorterer matchene etter hvor mye $ de har og finner den med mest\n",
    "            matched_companies.sort(key=lambda x: x[1], reverse=True)\n",
    "            max_budget = matched_companies[0][1]\n",
    "            #Tar ut de som har det høyeste budsejttet\n",
    "            max_budget_companies = [company for company, budget in matched_companies if budget == max_budget]\n",
    "            # Hvis det er mer enn 1 velger man random en av de\n",
    "            selected_company = random.choice(max_budget_companies)\n",
    "            \n",
    "            # trekker fra 1 i budsjettet\n",
    "            if local_companies[selected_company][-1] > 0:\n",
    "                local_companies[selected_company][-1] -= 1\n",
    "                revenue += 1  \n",
    "    \n",
    "    return revenue\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 31,
=======
   "execution_count": 683,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": 683,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "8b975413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trials using Balance Algorithm...\n",
      "-------------------------------------------\n",
      "Trial 1 - Revenue generated: 8\n",
      "Trial 2 - Revenue generated: 8\n",
      "Trial 3 - Revenue generated: 10\n",
      "Trial 4 - Revenue generated: 9\n",
      "Trial 5 - Revenue generated: 10\n",
      "Trial 6 - Revenue generated: 9\n",
      "Trial 7 - Revenue generated: 9\n",
      "Trial 8 - Revenue generated: 10\n",
      "Trial 9 - Revenue generated: 10\n",
      "Trial 10 - Revenue generated: 10\n",
      "-------------------------------------------\n",
      "Average revenue generated for all trials:  9.3\n"
     ]
    }
   ],
   "source": [
    "total_revenue = 0\n",
    "total_trials = 10\n",
    "print(\"Starting trials using Balance Algorithm...\")\n",
    "print(\"-------------------------------------------\")\n",
    "for i in range(total_trials):\n",
    "    local_companies = copy.deepcopy(global_companies)\n",
    "    revenue = balance_algorithm(local_companies, queries)\n",
    "    total_revenue = total_revenue + revenue\n",
    "    print(f\"Trial {i+1} - Revenue generated: {revenue}\")\n",
    "print(\"-------------------------------------------\")   \n",
    "print(\"Average revenue generated for all trials: \",total_revenue/total_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a2ef9e",
   "metadata": {},
   "source": [
    "### 5. Recommender System"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 42,
=======
   "execution_count": null,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": null,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "86174f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings matrix (each row corresponds to a movie, and each column corresponds to a user)\n",
    "ratings_matrix = np.array([\n",
    "    [1, 0, 3, 0, 0, 5, 0, 0, 5, 0, 4, 0],\n",
    "    [0, 0, 5, 4, 0, 0, 4, 0, 0, 2, 1, 3],\n",
    "    [2, 4, 0, 1, 2, 0, 3, 0, 4, 3, 5, 0],\n",
    "    [0, 2, 4, 0, 5, 0, 0, 4, 0, 0, 2, 0],\n",
    "    [0, 0, 4, 3, 4, 2, 0, 0, 0, 0, 2, 5],\n",
    "    [1, 0, 3, 0, 3, 0, 0, 2, 0, 0, 4, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c92e8e0",
   "metadata": {},
   "source": [
    "#### 5.1. User-User Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 69,
=======
   "execution_count": null,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": null,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "0749438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_cf(rate_m, tup_mu, neigh):\n",
    "    \n",
    "    # To-do! implement a user-user CF using cosine similarity as distance measure\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "    user_index, movie_index = tup_mu\n",
    "    num_users, num_movies = rate_m.shape\n",
    "\n",
    "    normalized_ratings = (rate_m - np.mean(rate_m, axis=1, keepdims=True)) / np.std(rate_m, axis=1, keepdims=True)\n",
    "    cosine_sim = np.dot(normalized_ratings, normalized_ratings.T)\n",
    "    norms = np.sqrt(np.diagonal(cosine_sim))\n",
    "    print(norms)\n",
    "    cosine_sim /= np.outer(norms, norms)\n",
    "    np.fill_diagonal(cosine_sim, 1) \n",
    "    \n",
    "    similar_indices = np.argsort(-cosine_sim[user_index])[:neigh+1]\n",
    "    if user_index in similar_indices:\n",
    "        similar_indices = similar_indices[similar_indices != user_index]\n",
    "    else:\n",
    "        similar_indices = similar_indices[:-1]\n",
    "\n",
    "    # Step 3: Predict the rating using weighted average of ratings by similar users\n",
    "    similar_users_similarities = cosine_sim[user_index, similar_indices]\n",
    "    similar_users_ratings = rate_m[similar_indices, movie_index]\n",
    "    \n",
    "    # Avoid division by zero by adding a small number to the denominator\n",
    "    prediction = np.dot(similar_users_similarities, similar_users_ratings) / (np.sum(similar_users_similarities) + 1e-10)\n",
    "    \n",
=======
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
    "    \n",
    "    return prediction   "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 66,
=======
   "execution_count": null,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": null,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "c153de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuple of movie rating by users to be predicted e.g (1, 5) refers to the rating of movie 1 by user 5\n",
    "list_mu_query = [(1, 5), (3, 3)]\n",
    "\n",
    "# Neighbor selection (|N|)\n",
    "neigh = 2"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 70,
=======
   "execution_count": null,
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
   "execution_count": null,
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
   "id": "22f8e8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
<<<<<<< HEAD
<<<<<<< HEAD
      "[3.46410162 3.46410162 3.46410162 3.46410162 3.46410162 3.46410162]\n",
      "The predicted rating of movie 1 by user 5: 2.2642320646545757 (User-User CF)\n",
      "-----------------------------------------------------------------\n",
      "[3.46410162 3.46410162 3.46410162 3.46410162 3.46410162 3.46410162]\n",
      "The predicted rating of movie 3 by user 3: 0.8125769339833091 (User-User CF)\n",
=======
      "The predicted rating of movie 1 by user 5: 1.42 (User-User CF)\n",
      "-----------------------------------------------------------------\n",
      "The predicted rating of movie 3 by user 3: 1.49 (User-User CF)\n",
>>>>>>> 14e5504804e8c1e7e284d84277c772ada4067449
=======
      "The predicted rating of movie 1 by user 5: 1.42 (User-User CF)\n",
      "-----------------------------------------------------------------\n",
      "The predicted rating of movie 3 by user 3: 1.49 (User-User CF)\n",
>>>>>>> 3465b4008c26fac6cec26eedd67fbdbff306da5c
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------------------------------------------\")   \n",
    "for mu_query in list_mu_query:\n",
    "    predicted_rating = user_cf(ratings_matrix, mu_query, neigh)\n",
    "    print(f\"The predicted rating of movie {mu_query[0]} by user {mu_query[1]}: {predicted_rating} (User-User CF)\")\n",
    "    print(\"-----------------------------------------------------------------\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7217e4ed",
   "metadata": {},
   "source": [
    "#### 5.2. Item-Item Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c03be5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_cf(rate_m, tup_mu, neigh):\n",
    "    \n",
    "    # To-do! implement a item-item CF using cosine similarity as distance measure\n",
    "    item_index, user_index = tup_mu  # This time the first entry is the item and the second is the user\n",
    "    num_items, num_users = rate_m.shape\n",
    "\n",
    "\n",
    "    normalized = (rate_m.T - np.mean(rate_m.T, axis=1, keepdims=True)) / np.std(rate_m.T, axis=1, keepdims=True)\n",
    "    sim = np.dot(normalized, normalized.T)\n",
    "    norms = np.sqrt(np.diagonal(sim))\n",
    "    sim /= np.outer(norms, norms)\n",
    "\n",
    "    similar_indices = np.argsort(-sim[item_index])[:neigh+1]\n",
    "    if item_index in similar_indices:\n",
    "        similar_indices = similar_indices[similar_indices != item_index]\n",
    "    else:\n",
    "        similar_indices = similar_indices[:-1]\n",
    "\n",
    "    similar_items_similarities = sim[item_index, similar_indices]\n",
    "    similar_items_ratings = rate_m[similar_indices, user_index]\n",
    "\n",
    "    if np.sum(similar_items_similarities) == 0:\n",
    "        prediction = np.mean(rate_m[item_index])  # Fallback to average rating if no similarities\n",
    "    else:\n",
    "        prediction = np.dot(similar_items_similarities, similar_items_ratings) / (np.sum(similar_items_similarities) + 1e-10)\n",
    "\n",
    "    return prediction\n",
    "\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c4b5ffe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 9 is out of bounds for axis 0 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-----------------------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)   \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mu_query \u001b[38;5;129;01min\u001b[39;00m list_mu_query:\n\u001b[0;32m----> 3\u001b[0m     predicted_rating \u001b[38;5;241m=\u001b[39m \u001b[43mitem_cf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mratings_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneigh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe predicted rating of movie \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmu_query[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by user \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmu_query[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_rating\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Item-Item CF)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-----------------------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)   \n",
      "Cell \u001b[0;32mIn[71], line 20\u001b[0m, in \u001b[0;36mitem_cf\u001b[0;34m(rate_m, tup_mu, neigh)\u001b[0m\n\u001b[1;32m     17\u001b[0m     similar_indices \u001b[38;5;241m=\u001b[39m similar_indices[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     19\u001b[0m similar_items_similarities \u001b[38;5;241m=\u001b[39m sim[item_index, similar_indices]\n\u001b[0;32m---> 20\u001b[0m similar_items_ratings \u001b[38;5;241m=\u001b[39m \u001b[43mrate_m\u001b[49m\u001b[43m[\u001b[49m\u001b[43msimilar_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(similar_items_similarities) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     23\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(rate_m[item_index])  \u001b[38;5;66;03m# Fallback to average rating if no similarities\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 9 is out of bounds for axis 0 with size 6"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------------------------------------------\")   \n",
    "for mu_query in list_mu_query:\n",
    "    predicted_rating = item_cf(ratings_matrix, mu_query, neigh)\n",
    "    print(f\"The predicted rating of movie {mu_query[0]} by user {mu_query[1]}: {predicted_rating} (Item-Item CF)\")\n",
    "    print(\"-----------------------------------------------------------------\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0892ce96",
   "metadata": {},
   "source": [
    "### Provide concise answers to all 5 cases in the Project 3 description below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc34aad",
   "metadata": {},
   "source": [
    "#### Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a669b54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b85a6",
   "metadata": {},
   "source": [
    "#### Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8340d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16cad2",
   "metadata": {},
   "source": [
    "#### Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97d9b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb9e628",
   "metadata": {},
   "source": [
    "#### Case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a78ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c341065",
   "metadata": {},
   "source": [
    "#### Case 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e3aa9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
